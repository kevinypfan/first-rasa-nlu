language: zh
pipeline:
  - name: HFTransformersNLP
    model_weights: "bert-base-chinese"
    model_name: "bert"
  - name: LanguageModelTokenizer
  - name: LanguageModelFeaturizer
  - name: CountVectorsFeaturizer
    analyzer: char_wb
    min_ngram: 1
    max_ngram: 4
  - name: DIETClassifier
    epochs: 30
    num_transformer_layers: 4
    transformer_size: 256
    use_masked_language_model: True
    drop_rate: 0.25
    weight_sparsity: 0.7
    batch_size: [64, 256]
    embedding_dimension: 30
    # hidden_layer_sizes:
    #   text: [512, 128]
